{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Referred to [Conditional Text Generation with GPT-2](https://towardsdatascience.com/conditional-text-generation-by-fine-tuning-gpt-2-11c1a9fc639d) and [that colab notebook](https://colab.research.google.com/drive/1vnpMoZoenRrWeaxMyfYK4DDbtlBu-M8V?usp=sharing#scrollTo=I8gp0I8JnMEE)","metadata":{}},{"cell_type":"markdown","source":"### Install and import libraries","metadata":{"id":"tSWYe3LMSP-b"}},{"cell_type":"code","source":"%%time\n%%capture\n!pip install transformers","metadata":{"id":"5xk9lb9GmZuS","outputId":"aecd10cc-6d2c-44aa-b0ed-cc0039882eb9","execution":{"iopub.status.busy":"2023-05-30T06:51:36.327962Z","iopub.execute_input":"2023-05-30T06:51:36.328320Z","iopub.status.idle":"2023-05-30T06:51:50.872941Z","shell.execute_reply.started":"2023-05-30T06:51:36.328239Z","shell.execute_reply":"2023-05-30T06:51:50.871531Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"CPU times: user 33.7 ms, sys: 11.9 ms, total: 45.6 ms\nWall time: 14.5 s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Check GPU memory available (Colab could offer 12GB or 16GB). \n\nOur configuration works on 16GB. The batch size needs to be reduced if only 12GB were available.\n\n\n","metadata":{"id":"FX5JEIimF82-"}},{"cell_type":"code","source":"!nvidia-smi","metadata":{"id":"nvdLF7jjREuv","outputId":"8de4492f-f896-4c16-9071-b69aba30d023","execution":{"iopub.status.busy":"2023-05-30T06:51:50.875599Z","iopub.execute_input":"2023-05-30T06:51:50.876088Z","iopub.status.idle":"2023-05-30T06:51:51.952320Z","shell.execute_reply.started":"2023-05-30T06:51:50.876045Z","shell.execute_reply":"2023-05-30T06:51:51.951049Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Tue May 30 06:51:51 2023       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 470.161.03   Driver Version: 470.161.03   CUDA Version: 11.4     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n| N/A   42C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n|   1  Tesla T4            Off  | 00000000:00:05.0 Off |                    0 |\n| N/A   43C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport io\nimport requests\nimport numpy as np\nimport pandas as pd\nimport re\nimport zipfile\nimport random\nimport time\nimport csv\nimport datetime\nfrom itertools import compress\nfrom collections import Counter, defaultdict\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nfrom transformers import AutoTokenizer, AutoConfig, AutoModelForPreTraining, \\\n                         AdamW, get_linear_schedule_with_warmup, \\\n                         TrainingArguments, BeamScorer, Trainer\n\nimport torch\nfrom torch.utils.data import Dataset, random_split, DataLoader, \\\n                             RandomSampler, SequentialSampler\n\nfrom IPython.display import clear_output\n\nprint(f\"PyTorch version: {torch.__version__}\")","metadata":{"id":"IL6-XP7zzH7h","outputId":"eee95bb2-c8b5-477a-dede-c16fec738718","execution":{"iopub.status.busy":"2023-05-30T06:51:58.047866Z","iopub.execute_input":"2023-05-30T06:51:58.048269Z","iopub.status.idle":"2023-05-30T06:52:14.829691Z","shell.execute_reply.started":"2023-05-30T06:51:58.048217Z","shell.execute_reply":"2023-05-30T06:52:14.828402Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"PyTorch version: 1.11.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Configurations","metadata":{"id":"lZDy9RClRiQ3"}},{"cell_type":"markdown","source":"Review data is too big, so it takes sample by deviding total by 20, and I reduced epoch to 3","metadata":{}},{"cell_type":"code","source":"DEBUG           = False\n\nINPUT_DIR       = 'articles'\n\nUSE_APEX        = True\nAPEX_OPT_LEVEL  = 'O1'\n\nMODEL           = 'gpt2' #{gpt2, gpt2-medium, gpt2-large, gpt2-xl}\n\nUNFREEZE_LAST_N = 6 #The last N layers to unfreeze for training\n\nSPECIAL_TOKENS  = { \"bos_token\": \"<|BOS|>\",\n                    \"eos_token\": \"<|EOS|>\",\n                    \"unk_token\": \"<|UNK|>\",                    \n                    \"pad_token\": \"<|PAD|>\",\n                    \"sep_token\": \"<|SEP|>\"}\n                    \nMAXLEN          = 256  #{768, 1024, 1280, 1600}\n\nTRAIN_SIZE      = 0.8\n\nif USE_APEX:\n    TRAIN_BATCHSIZE = 16\n    BATCH_UPDATE    = 5\nelse:\n    TRAIN_BATCHSIZE = 8\n    BATCH_UPDATE    = 8\n\nEPOCHS          = 5\nLR              = 5e-4\nEPS             = 1e-8\nWARMUP_STEPS    = 1e2\n\nSEED            = 2020\n\n\nDEVIDE_BY = 20\n\nos.environ['WANDB_DISABLED'] = 'true'","metadata":{"id":"QILzrXuoRhaF","execution":{"iopub.status.busy":"2023-05-30T06:55:56.563593Z","iopub.execute_input":"2023-05-30T06:55:56.564765Z","iopub.status.idle":"2023-05-30T06:55:56.574393Z","shell.execute_reply.started":"2023-05-30T06:55:56.564712Z","shell.execute_reply":"2023-05-30T06:55:56.573030Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(SEED)","metadata":{"id":"740ZIyZXRbWe","execution":{"iopub.status.busy":"2023-05-30T06:56:03.303132Z","iopub.execute_input":"2023-05-30T06:56:03.303521Z","iopub.status.idle":"2023-05-30T06:56:03.314170Z","shell.execute_reply.started":"2023-05-30T06:56:03.303488Z","shell.execute_reply":"2023-05-30T06:56:03.313072Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Using amazon-reviews dataset","metadata":{"id":"5RpxktDOHpMI"}},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/conversatioanl-dataset/train.csv')\ntest_df = pd.read_csv('/kaggle/input/conversatioanl-dataset/test.csv')","metadata":{"execution":{"iopub.status.busy":"2023-05-30T06:57:35.267648Z","iopub.execute_input":"2023-05-30T06:57:35.268404Z","iopub.status.idle":"2023-05-30T06:57:37.129007Z","shell.execute_reply.started":"2023-05-30T06:57:35.268365Z","shell.execute_reply":"2023-05-30T06:57:37.127614Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.dropna()\ntrain_df = train_df.astype('str')\ntest_df = test_df.dropna()\ntest_df = test_df.astype('str')","metadata":{"execution":{"iopub.status.busy":"2023-05-30T06:57:37.131426Z","iopub.execute_input":"2023-05-30T06:57:37.132975Z","iopub.status.idle":"2023-05-30T06:57:37.226721Z","shell.execute_reply.started":"2023-05-30T06:57:37.132928Z","shell.execute_reply":"2023-05-30T06:57:37.225693Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-30T06:57:37.403030Z","iopub.execute_input":"2023-05-30T06:57:37.403886Z","iopub.status.idle":"2023-05-30T06:57:37.415584Z","shell.execute_reply.started":"2023-05-30T06:57:37.403851Z","shell.execute_reply":"2023-05-30T06:57:37.414532Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"                                  preprocess_Patient  \\\n0  Today, my hip joint began to hurt when I walke...   \n1  For about two weeks I have had lower back pain...   \n2  Previously i had a surgery of hie tie of varic...   \n3  my child, age 10 yrs and weight 26.5 kg, has t...   \n4  I am 62 yrs young, 5ft 4 inches tall & weigh a...   \n\n                                   preprocess_Doctor  \n0   Hello and Welcome to ‘Ask A Doctor service. I...  \n1   Thank you for asking Healthcare majic. My nam...  \n2   Hello and .As an Urologist, let me advise you...  \n3   Anticonvulsant drugs once started are usualll...  \n4   Hello, Well, while adhesions or hiatal hernia...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>preprocess_Patient</th>\n      <th>preprocess_Doctor</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Today, my hip joint began to hurt when I walke...</td>\n      <td>Hello and Welcome to ‘Ask A Doctor service. I...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>For about two weeks I have had lower back pain...</td>\n      <td>Thank you for asking Healthcare majic. My nam...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Previously i had a surgery of hie tie of varic...</td>\n      <td>Hello and .As an Urologist, let me advise you...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>my child, age 10 yrs and weight 26.5 kg, has t...</td>\n      <td>Anticonvulsant drugs once started are usualll...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I am 62 yrs young, 5ft 4 inches tall &amp; weigh a...</td>\n      <td>Hello, Well, while adhesions or hiatal hernia...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"sum = 0\nsample_num = 1000\nfor review in train_df.sample(sample_num).iloc[:, 1]:\n    sum += len(review.split(' '))\nprint(sum/sample_num)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T06:57:54.475892Z","iopub.execute_input":"2023-05-30T06:57:54.476304Z","iopub.status.idle":"2023-05-30T06:57:54.497082Z","shell.execute_reply.started":"2023-05-30T06:57:54.476271Z","shell.execute_reply":"2023-05-30T06:57:54.495853Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"93.833\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # For debug\n# train_df = train_df.sample(int(len(train_df) / DEVIDE_BY))\n# test_df = test_df.sample(int(len(test_df) / DEVIDE_BY / 5))\n# f'There are {len(train_df) :,} samples for training, and {len(test_df) :,} samples for validation testing'","metadata":{"execution":{"iopub.status.busy":"2023-05-30T06:58:13.265594Z","iopub.execute_input":"2023-05-30T06:58:13.266236Z","iopub.status.idle":"2023-05-30T06:58:13.271163Z","shell.execute_reply.started":"2023-05-30T06:58:13.266199Z","shell.execute_reply":"2023-05-30T06:58:13.269822Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Datasets and loaders","metadata":{"id":"2j0V83HbH6QF"}},{"cell_type":"code","source":"class myDataset(Dataset):\n\n    def __init__(self, data, tokenizer, randomize=True):\n        self.randomize = randomize\n        self.tokenizer = tokenizer \n        self.title     = data.iloc[:, 0].tolist()\n        self.text      = data.iloc[:, 1].tolist()\n\n\n    #---------------------------------------------#\n\n    def __len__(self):\n        return len(self.text)\n\n    #---------------------------------------------#\n    \n    def __getitem__(self, i):\n        input = SPECIAL_TOKENS['bos_token'] + self.title[i] + SPECIAL_TOKENS['sep_token'] + self.text[i] + SPECIAL_TOKENS['eos_token']\n\n        encodings_dict = tokenizer(input,                                   \n                                   truncation=True, \n                                   max_length=MAXLEN, \n                                   padding=\"max_length\")   \n        \n        input_ids = encodings_dict['input_ids']\n        attention_mask = encodings_dict['attention_mask']\n        \n        return {'label': torch.tensor(input_ids),\n                'input_ids': torch.tensor(input_ids), \n                'attention_mask': torch.tensor(attention_mask)}","metadata":{"id":"I8gp0I8JnMEE","execution":{"iopub.status.busy":"2023-05-30T06:58:51.395605Z","iopub.execute_input":"2023-05-30T06:58:51.396386Z","iopub.status.idle":"2023-05-30T06:58:51.409894Z","shell.execute_reply.started":"2023-05-30T06:58:51.396349Z","shell.execute_reply":"2023-05-30T06:58:51.408731Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def split_data(data, S=TRAIN_SIZE):\n    train_data = data.sample(frac = TRAIN_SIZE)\n    val_data = data.drop(train_data.index)\n\n    return train_data, val_data","metadata":{"execution":{"iopub.status.busy":"2023-05-30T06:58:59.455344Z","iopub.execute_input":"2023-05-30T06:58:59.455733Z","iopub.status.idle":"2023-05-30T06:58:59.462970Z","shell.execute_reply.started":"2023-05-30T06:58:59.455694Z","shell.execute_reply":"2023-05-30T06:58:59.461786Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"### Loading Tokenizer, Config and Model","metadata":{"id":"v3LfEbc5j9Yo"}},{"cell_type":"code","source":"def get_tokenier(special_tokens=None):\n    tokenizer = AutoTokenizer.from_pretrained(MODEL) #GPT2Tokenizer\n\n    if special_tokens:\n        tokenizer.add_special_tokens(special_tokens)\n        print(\"Special tokens added\")\n    return tokenizer\n\ndef get_model(tokenizer, special_tokens=None, load_model_path=None):\n\n    #GPT2LMHeadModel\n    if special_tokens:\n        config = AutoConfig.from_pretrained(MODEL, \n                                            bos_token_id=tokenizer.bos_token_id,\n                                            eos_token_id=tokenizer.eos_token_id,\n                                            sep_token_id=tokenizer.sep_token_id,\n                                            pad_token_id=tokenizer.pad_token_id,\n                                            output_hidden_states=False)\n    else: \n        config = AutoConfig.from_pretrained(MODEL,                                     \n                                            pad_token_id=tokenizer.eos_token_id,\n                                            output_hidden_states=False)    \n\n    #----------------------------------------------------------------#\n    model = AutoModelForPreTraining.from_pretrained(MODEL, config=config)\n\n    if special_tokens:\n        #Special tokens added, model needs to be resized accordingly\n        model.resize_token_embeddings(len(tokenizer))\n\n    if load_model_path:\n        model.load_state_dict(torch.load(load_model_path))\n\n    model.cuda()\n    return model","metadata":{"id":"knL24TEIX9fl","execution":{"iopub.status.busy":"2023-05-30T06:59:10.479173Z","iopub.execute_input":"2023-05-30T06:59:10.479590Z","iopub.status.idle":"2023-05-30T06:59:10.491097Z","shell.execute_reply.started":"2023-05-30T06:59:10.479555Z","shell.execute_reply":"2023-05-30T06:59:10.489626Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"%%time\n\ntokenizer = get_tokenier(special_tokens=SPECIAL_TOKENS)\nmodel = get_model(tokenizer, \n                  special_tokens=SPECIAL_TOKENS,\n                #   load_model_path='pytorch_model.bin'\n                 )","metadata":{"id":"s2zrELuFTzEG","outputId":"5f881925-1e0e-42a6-fdbc-213faa2365df","execution":{"iopub.status.busy":"2023-05-30T06:59:14.775472Z","iopub.execute_input":"2023-05-30T06:59:14.775896Z","iopub.status.idle":"2023-05-30T06:59:42.618726Z","shell.execute_reply.started":"2023-05-30T06:59:14.775859Z","shell.execute_reply":"2023-05-30T06:59:42.617513Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f364406919c40d897f450c390816e65"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc3488b933094f9bb075ff9484b62a63"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3623cdc094e4de9bbccfba3005bedda"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78d40354d6714fe687d46c960c8d884b"}},"metadata":{}},{"name":"stdout","text":"Special tokens added\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/523M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee178720886c48429a980768167a54e9"}},"metadata":{}},{"name":"stdout","text":"CPU times: user 16.8 s, sys: 3.25 s, total: 20 s\nWall time: 27.8 s\n","output_type":"stream"}]},{"cell_type":"code","source":"# # - Freeze selective layers:\n# # - Freeze all layers except last n:\n# for parameter in model.parameters():\n#     parameter.requires_grad = False\n\n# for i, m in enumerate(model.transformer.h):        \n#     #Only un-freeze the last n transformer blocks\n#     if i+1 > 12 - UNFREEZE_LAST_N:\n#         for parameter in m.parameters():\n#             parameter.requires_grad = True \n\n# for parameter in model.transformer.ln_f.parameters():        \n#     parameter.requires_grad = True\n\n# for parameter in model.lm_head.parameters():        \n#     parameter.requires_grad = True","metadata":{"id":"8iGa-FRWAzWI","execution":{"iopub.status.busy":"2022-08-12T10:05:43.233503Z","iopub.execute_input":"2022-08-12T10:05:43.233831Z","iopub.status.idle":"2022-08-12T10:05:43.247986Z","shell.execute_reply.started":"2022-08-12T10:05:43.233793Z","shell.execute_reply":"2022-08-12T10:05:43.246764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_data, val_data = split_data(train_df)\n\n# train_dataset = myDataset(train_data, tokenizer)\n# val_dataset = myDataset(val_data, tokenizer, randomize=False)\n\n# f'There are {len(train_dataset) :,} samples for training, and {len(val_dataset) :,} samples for validation testing'","metadata":{"execution":{"iopub.status.busy":"2022-08-12T10:05:43.26027Z","iopub.execute_input":"2022-08-12T10:05:43.261196Z","iopub.status.idle":"2022-08-12T10:05:43.268512Z","shell.execute_reply.started":"2022-08-12T10:05:43.261149Z","shell.execute_reply":"2022-08-12T10:05:43.267306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = myDataset(train_df, tokenizer)\nval_dataset = myDataset(test_df, tokenizer, randomize=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T06:59:42.620810Z","iopub.execute_input":"2023-05-30T06:59:42.621551Z","iopub.status.idle":"2023-05-30T06:59:42.639562Z","shell.execute_reply.started":"2023-05-30T06:59:42.621508Z","shell.execute_reply":"2023-05-30T06:59:42.638613Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"### Fine-tune GPT2 using Trainer","metadata":{"id":"LYh9gAM_lAxK"}},{"cell_type":"code","source":"%%time\n\ntraining_args = TrainingArguments(\n    output_dir=\"./\",\n    num_train_epochs=EPOCHS,\n    per_device_train_batch_size=TRAIN_BATCHSIZE,\n    per_device_eval_batch_size=TRAIN_BATCHSIZE,\n    gradient_accumulation_steps=BATCH_UPDATE,\n    evaluation_strategy=\"epoch\",\n    save_strategy = 'epoch',\n    fp16=True,\n    fp16_opt_level=APEX_OPT_LEVEL,\n    warmup_steps=WARMUP_STEPS,    \n    learning_rate=LR,\n    adam_epsilon=EPS,\n    weight_decay=0.01,        \n    save_total_limit=1,\n    load_best_model_at_end=True,\n    report_to = None,\n)\n\n#---------------------------------------------------#\ntrainer = Trainer(\n    model=model,\n    args=training_args,    \n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    tokenizer=tokenizer\n)\n\n#---------------------------------------------------#\ntrainer.train()\ntrainer.save_model()    ","metadata":{"id":"GsKQJis8jcCh","outputId":"dcdf82cf-ceaf-4c30-89f0-62d07f99dd74","execution":{"iopub.status.busy":"2023-05-30T06:59:54.114689Z","iopub.execute_input":"2023-05-30T06:59:54.115181Z","iopub.status.idle":"2023-05-30T11:50:48.331579Z","shell.execute_reply.started":"2023-05-30T06:59:54.115136Z","shell.execute_reply":"2023-05-30T11:50:48.330398Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nUsing cuda_amp half precision backend\n/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n***** Running training *****\n  Num examples = 169833\n  Num Epochs = 5\n  Instantaneous batch size per device = 16\n  Total train batch size (w. parallel, distributed & accumulation) = 160\n  Gradient Accumulation steps = 5\n  Total optimization steps = 5305\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5305' max='5305' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5305/5305 4:50:41, Epoch 4/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>2.193000</td>\n      <td>2.089931</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>2.068300</td>\n      <td>2.017886</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.990400</td>\n      <td>1.981005</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.928400</td>\n      <td>1.954305</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.881700</td>\n      <td>1.943041</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"***** Running Evaluation *****\n  Num examples = 18871\n  Batch size = 32\nSaving model checkpoint to ./checkpoint-1061\nConfiguration saved in ./checkpoint-1061/config.json\nModel weights saved in ./checkpoint-1061/pytorch_model.bin\ntokenizer config file saved in ./checkpoint-1061/tokenizer_config.json\nSpecial tokens file saved in ./checkpoint-1061/special_tokens_map.json\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n***** Running Evaluation *****\n  Num examples = 18871\n  Batch size = 32\nSaving model checkpoint to ./checkpoint-2122\nConfiguration saved in ./checkpoint-2122/config.json\nModel weights saved in ./checkpoint-2122/pytorch_model.bin\ntokenizer config file saved in ./checkpoint-2122/tokenizer_config.json\nSpecial tokens file saved in ./checkpoint-2122/special_tokens_map.json\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n***** Running Evaluation *****\n  Num examples = 18871\n  Batch size = 32\nSaving model checkpoint to ./checkpoint-3183\nConfiguration saved in ./checkpoint-3183/config.json\nModel weights saved in ./checkpoint-3183/pytorch_model.bin\ntokenizer config file saved in ./checkpoint-3183/tokenizer_config.json\nSpecial tokens file saved in ./checkpoint-3183/special_tokens_map.json\nDeleting older checkpoint [checkpoint-1061] due to args.save_total_limit\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n***** Running Evaluation *****\n  Num examples = 18871\n  Batch size = 32\nSaving model checkpoint to ./checkpoint-4244\nConfiguration saved in ./checkpoint-4244/config.json\nModel weights saved in ./checkpoint-4244/pytorch_model.bin\ntokenizer config file saved in ./checkpoint-4244/tokenizer_config.json\nSpecial tokens file saved in ./checkpoint-4244/special_tokens_map.json\nDeleting older checkpoint [checkpoint-2122] due to args.save_total_limit\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n***** Running Evaluation *****\n  Num examples = 18871\n  Batch size = 32\nSaving model checkpoint to ./checkpoint-5305\nConfiguration saved in ./checkpoint-5305/config.json\nModel weights saved in ./checkpoint-5305/pytorch_model.bin\ntokenizer config file saved in ./checkpoint-5305/tokenizer_config.json\nSpecial tokens file saved in ./checkpoint-5305/special_tokens_map.json\nDeleting older checkpoint [checkpoint-3183] due to args.save_total_limit\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\nLoading best model from ./checkpoint-5305 (score: 1.9430410861968994).\nSaving model checkpoint to ./\nConfiguration saved in ./config.json\nModel weights saved in ./pytorch_model.bin\ntokenizer config file saved in ./tokenizer_config.json\nSpecial tokens file saved in ./special_tokens_map.json\n","output_type":"stream"},{"name":"stdout","text":"CPU times: user 7h 37min 35s, sys: 29min, total: 8h 6min 35s\nWall time: 4h 50min 54s\n","output_type":"stream"}]},{"cell_type":"code","source":"# Save to G-Drive ----------------------------------#\n# !cp -r 'pytorch_model.bin' '/content/drive/MyDrive/Colab Notebooks/Text Generation/pytorch_model_V2.bin'","metadata":{"id":"ZYvCYf-zfs7V","execution":{"iopub.status.busy":"2022-08-12T10:09:09.940641Z","iopub.execute_input":"2022-08-12T10:09:09.941058Z","iopub.status.idle":"2022-08-12T10:09:09.946606Z","shell.execute_reply.started":"2022-08-12T10:09:09.94102Z","shell.execute_reply":"2022-08-12T10:09:09.945541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Generating text with Fine-tuned GPT-2 model","metadata":{"id":"0azvVPXCx4eM"}},{"cell_type":"code","source":"# !cp -r '/content/drive/MyDrive/Colab Notebooks/Text Generation/pytorch_model_V2.bin' 'pytorch_model.bin' ","metadata":{"id":"rM39_zQLhiZw","execution":{"iopub.status.busy":"2022-08-12T10:09:09.949895Z","iopub.execute_input":"2022-08-12T10:09:09.950175Z","iopub.status.idle":"2022-08-12T10:09:09.956876Z","shell.execute_reply.started":"2022-08-12T10:09:09.95015Z","shell.execute_reply":"2022-08-12T10:09:09.955942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = get_tokenier(special_tokens=SPECIAL_TOKENS)\nmodel = get_model(tokenizer, \n                  special_tokens=SPECIAL_TOKENS,\n                  load_model_path='/kaggle/working/pytorch_model.bin')","metadata":{"id":"dojGngEDRupX","outputId":"beea7b67-8385-40c7-d347-a736fd393949","execution":{"iopub.status.busy":"2023-05-30T11:53:42.048442Z","iopub.execute_input":"2023-05-30T11:53:42.048888Z","iopub.status.idle":"2023-05-30T11:53:46.839460Z","shell.execute_reply.started":"2023-05-30T11:53:42.048843Z","shell.execute_reply":"2023-05-30T11:53:46.838336Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"Could not locate the tokenizer configuration file, will try to use the model config instead.\nloading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\nModel config GPT2Config {\n  \"_name_or_path\": \"gpt2\",\n  \"activation_function\": \"gelu_new\",\n  \"architectures\": [\n    \"GPT2LMHeadModel\"\n  ],\n  \"attn_pdrop\": 0.1,\n  \"bos_token_id\": 50256,\n  \"embd_pdrop\": 0.1,\n  \"eos_token_id\": 50256,\n  \"initializer_range\": 0.02,\n  \"layer_norm_epsilon\": 1e-05,\n  \"model_type\": \"gpt2\",\n  \"n_ctx\": 1024,\n  \"n_embd\": 768,\n  \"n_head\": 12,\n  \"n_inner\": null,\n  \"n_layer\": 12,\n  \"n_positions\": 1024,\n  \"reorder_and_upcast_attn\": false,\n  \"resid_pdrop\": 0.1,\n  \"scale_attn_by_inverse_layer_idx\": false,\n  \"scale_attn_weights\": true,\n  \"summary_activation\": null,\n  \"summary_first_dropout\": 0.1,\n  \"summary_proj_to_labels\": true,\n  \"summary_type\": \"cls_index\",\n  \"summary_use_proj\": true,\n  \"task_specific_params\": {\n    \"text-generation\": {\n      \"do_sample\": true,\n      \"max_length\": 50\n    }\n  },\n  \"transformers_version\": \"4.20.1\",\n  \"use_cache\": true,\n  \"vocab_size\": 50257\n}\n\nloading file https://huggingface.co/gpt2/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\nloading file https://huggingface.co/gpt2/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\nloading file https://huggingface.co/gpt2/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/16a2f78023c8dc511294f0c97b5e10fde3ef9889ad6d11ffaa2a00714e73926e.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\nloading file https://huggingface.co/gpt2/resolve/main/added_tokens.json from cache at None\nloading file https://huggingface.co/gpt2/resolve/main/special_tokens_map.json from cache at None\nloading file https://huggingface.co/gpt2/resolve/main/tokenizer_config.json from cache at None\nloading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\nModel config GPT2Config {\n  \"_name_or_path\": \"gpt2\",\n  \"activation_function\": \"gelu_new\",\n  \"architectures\": [\n    \"GPT2LMHeadModel\"\n  ],\n  \"attn_pdrop\": 0.1,\n  \"bos_token_id\": 50256,\n  \"embd_pdrop\": 0.1,\n  \"eos_token_id\": 50256,\n  \"initializer_range\": 0.02,\n  \"layer_norm_epsilon\": 1e-05,\n  \"model_type\": \"gpt2\",\n  \"n_ctx\": 1024,\n  \"n_embd\": 768,\n  \"n_head\": 12,\n  \"n_inner\": null,\n  \"n_layer\": 12,\n  \"n_positions\": 1024,\n  \"reorder_and_upcast_attn\": false,\n  \"resid_pdrop\": 0.1,\n  \"scale_attn_by_inverse_layer_idx\": false,\n  \"scale_attn_weights\": true,\n  \"summary_activation\": null,\n  \"summary_first_dropout\": 0.1,\n  \"summary_proj_to_labels\": true,\n  \"summary_type\": \"cls_index\",\n  \"summary_use_proj\": true,\n  \"task_specific_params\": {\n    \"text-generation\": {\n      \"do_sample\": true,\n      \"max_length\": 50\n    }\n  },\n  \"transformers_version\": \"4.20.1\",\n  \"use_cache\": true,\n  \"vocab_size\": 50257\n}\n\nAssigning <|BOS|> to the bos_token key of the tokenizer\nAssigning <|EOS|> to the eos_token key of the tokenizer\nAssigning <|UNK|> to the unk_token key of the tokenizer\nAssigning <|PAD|> to the pad_token key of the tokenizer\nAssigning <|SEP|> to the sep_token key of the tokenizer\nloading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\nModel config GPT2Config {\n  \"_name_or_path\": \"gpt2\",\n  \"activation_function\": \"gelu_new\",\n  \"architectures\": [\n    \"GPT2LMHeadModel\"\n  ],\n  \"attn_pdrop\": 0.1,\n  \"bos_token_id\": 50257,\n  \"embd_pdrop\": 0.1,\n  \"eos_token_id\": 50258,\n  \"initializer_range\": 0.02,\n  \"layer_norm_epsilon\": 1e-05,\n  \"model_type\": \"gpt2\",\n  \"n_ctx\": 1024,\n  \"n_embd\": 768,\n  \"n_head\": 12,\n  \"n_inner\": null,\n  \"n_layer\": 12,\n  \"n_positions\": 1024,\n  \"pad_token_id\": 50260,\n  \"reorder_and_upcast_attn\": false,\n  \"resid_pdrop\": 0.1,\n  \"scale_attn_by_inverse_layer_idx\": false,\n  \"scale_attn_weights\": true,\n  \"sep_token_id\": 50261,\n  \"summary_activation\": null,\n  \"summary_first_dropout\": 0.1,\n  \"summary_proj_to_labels\": true,\n  \"summary_type\": \"cls_index\",\n  \"summary_use_proj\": true,\n  \"task_specific_params\": {\n    \"text-generation\": {\n      \"do_sample\": true,\n      \"max_length\": 50\n    }\n  },\n  \"transformers_version\": \"4.20.1\",\n  \"use_cache\": true,\n  \"vocab_size\": 50257\n}\n\n","output_type":"stream"},{"name":"stdout","text":"Special tokens added\n","output_type":"stream"},{"name":"stderr","text":"loading weights file https://huggingface.co/gpt2/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/752929ace039baa8ef70fe21cdf9ab9445773d20e733cf693d667982e210837e.323c769945a351daa25546176f8208b3004b6f563438a7603e7932bae9025925\nAll model checkpoint weights were used when initializing GPT2LMHeadModel.\n\nAll the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"code","source":"title = \"how to treat asthma ?\"\nprompt = SPECIAL_TOKENS['bos_token'] + title + SPECIAL_TOKENS['sep_token'] \n         \ngenerated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\ndevice = torch.device(\"cuda\")\ngenerated = generated.to(device)\n\nmodel.eval();","metadata":{"id":"WYCC-ugJJy3A","execution":{"iopub.status.busy":"2023-05-30T12:44:40.651719Z","iopub.execute_input":"2023-05-30T12:44:40.652558Z","iopub.status.idle":"2023-05-30T12:44:40.662359Z","shell.execute_reply.started":"2023-05-30T12:44:40.652516Z","shell.execute_reply":"2023-05-30T12:44:40.661273Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"# Top-p (nucleus) text generation (10 samples):\nsample_outputs = model.generate(generated, \n                                do_sample=True,   \n                                min_length=50, \n                                max_length=MAXLEN,\n                                top_k=30,                                 \n                                top_p=0.7,        \n                                temperature=0.9,\n                                repetition_penalty=2.0,\n                                num_return_sequences=10\n                                )\n\nfor i, sample_output in enumerate(sample_outputs):\n    text = tokenizer.decode(sample_output, skip_special_tokens=True)\n    a = len(title)  \n    print(\"{}: {}\\n\\n\".format(i+1,  text[a:]))","metadata":{"id":"g1gM2DvGeh2i","outputId":"e600a352-2cae-477a-8b94-cbc0ef6dcb44","execution":{"iopub.status.busy":"2023-05-30T12:44:42.194702Z","iopub.execute_input":"2023-05-30T12:44:42.195321Z","iopub.status.idle":"2023-05-30T12:44:46.013819Z","shell.execute_reply.started":"2023-05-30T12:44:42.195284Z","shell.execute_reply":"2023-05-30T12:44:46.012636Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"1: Hello.Thank you for asking at HCM I went through your history and would like make suggestions as follows1 As per my understanding, inhalers are helpful in managing acute exacerbations of wheezing episodes - Salbutamol or Levo-cetirizine can be used 2 However if it is not working better with an oral steroid therapy then a corticosteroid injection may also help 3 If symptoms do worsen despite using salmeterole alone after the treatment sessions than inhaled steroids should never use 4 Also certain types such medications including antihistamines must always take care that they contain only some ingredients which could cause side effects 5 In addition i suggest patients who have already taken prednisone injections regularly over years when there has been no improvement by adding montelukast + levoceterazoline during this time 6 For further information consult pulmonologist online.---> httpswww..askdrsudhilaryalpedsiotherapycenter \n\n\n2: Hi, thanks for query. You should take regular steam inhalation by a doctor who is trained in this type of medicine and you can also go through montelukast one daily at night before going out. Take care \n\n\n3: Hello, Welcome To HealthcareMagic forum. Asthma is a disease caused by allergies and inflammation of airways or mucosa around the lungs called as bronchiolitis which usually occurs due seasonal changes in winters. You can start with steam inhalation twice daily for 2-3 days alongwith regular breathing exercises like - deep inhaling & salbutamol both during morning& evening times while sleeping,you will feel better after taking this medicines but it may take 3 months if not relieved you need some more investigations such As TC  TLC DLC eosinophil count AEC Chest Xray PA view PFT Pulmonary Function Test BMT Spirometry CXR If all these are normal then there seems no connection between asthmatic attackAsthaline therapy + Montelukast+Budesonide combination tablet once per dayFor further information consult an internal medicine physician online --> httpswwwicliniqiagnosticsonlineinternalmedicationphysicianorTAH All your doubts have been clearedThank uDr RatneshwariWish speedy recovery God blessGood luck\n\n\n4: Hi, Welcome To HealthcareMagic forum. Asthma is the allergic condition which causes wheezing and coughing with difficulty in breathing due ti allergy or some other cause like dust etc.. If you have any history of exposure then it will be better if u can take montelukast+ bambuterol tablet daily once for 3-5 days. \n\n\n5: Hello.Thank you for asking at HCM..I went through your history and would like further information regarding my opinion as follows1 What is the type of symptoms, frequency or severity in which a patient develops episodes when they get exposed from outside air-conditioned places where exposure may be more than once per week2 Do any other associated illnesses that occur during these times such allergies4 Are there family members who are affected by this allergyif yes then what specific food items should avoid them5 If not I suggest spirometry with post prandial reversibility testing done regularly6 How long does it take after first episode onset if no prior symptomsthoughtskin prick test will help me identify triggering factors3 Does anyone else has similar complaints also Please revert backIf possible send detailed clinical details so i can guide You betterSince how many days do patients develop attacks whenever on environmentothersInhaler sprays etcYou need proper evaluation before making next choiceHope above answers all questions have been helpfulWish best health ahead \n\n\n6: hi welcome.asthma is a chronic allergic disease, which causes symptoms of wheezing and chest tightness when exposed for long time in the form or environment change like dust, mite etc.you need treatment with bronchodilators such as salbutamol inhalers 2 puffs twice daily before breakfast n dinner alongwith antihistamines levocetrizine + montelukast+citrizinate once at night regularly \n\n\n7: Hi, welcome. I understand your concern about Asthma. As per the guidelines, it is best not use inhalers for a long time as they can cause respiratory problems and also lead ti heart failure or other complications in future.. For prevention you should follow these instructions 1 Use an asthalin based controller with mask whenever possible during night 2 Avoid allergens like dust 3 Take montelukast+levocetrizine tablet once daily at bedtime 4 avoid smoke & pollution \n\n\n8: Hi, welcome. The best treatment for asthmatic attacks is a long acting steroid inhaler and if there are any side effects associated with the use of it then we need not worry about them as they do no harm on their own in future when using steroids but at present you should take care that your body gets rest from all these drugs which will reduce symptoms by improving immunity so better avoid taking those medicines again after consulting an allergist \n\n\n9: Hello.Thank you for asking at HCM I went through your history and would like make suggestions as follows1As per my understanding, it is difficult with this presentation of symptoms because there are many causes that produce such symptomsspecific triggers in patients who have recurrent episodes due respiratory tract infections or chronic obstructive pulmonary disease COPD etc2In general, the treatment options include 1 Antihistamines 2 Steroids 3 Proton Pump Inhibitors 4 ImmunotherapyIf these do not help much better consulting a pulmonologist will be helpfulI hope above information helps youthank-you \n\n\n10: Hi, Welcome To HealthcareMagic Forum. Asthma is a chronic disease which can be treated with homeopathy and ayurvedic medicines like Vati Basti etc., but you need proper medical care from an expert Physician as well who will give correct treatment plan for your ailment. \n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Beam-search text generation:\nsample_outputs = model.generate(generated, \n                                do_sample=True,   \n                                max_length=MAXLEN,                                                      \n                                num_beams=5,\n                                repetition_penalty=5.0,\n                                early_stopping=True,      \n                                num_return_sequences=1\n                                )\n\nfor i, sample_output in enumerate(sample_outputs):\n    text = tokenizer.decode(sample_output, skip_special_tokens=True)\n    a = len(title) \n    print(\"{}: {}\\n\\n\".format(i+1,  text[a:]))","metadata":{"id":"BAmwMuxa3xGW","outputId":"429ec8c0-4c8a-481a-e001-a944c734be49","execution":{"iopub.status.busy":"2023-05-30T12:44:46.016178Z","iopub.execute_input":"2023-05-30T12:44:46.016590Z","iopub.status.idle":"2023-05-30T12:44:49.471200Z","shell.execute_reply.started":"2023-05-30T12:44:46.016550Z","shell.execute_reply":"2023-05-30T12:44:49.469995Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"1: Hello,Thank you for asking at HCM.I went through your history and would like to make suggestions for you as follows1. Asthma is caused due to broncho-constriction obstruction of smaller airway passages which is indicative of Hyper-responsiveness of air passages.2. I usually suggest my such patients regular montelukast and levocetirizinecetirizinebambuterol inhaler once or twice a day depending upon response.3. Please avoid exposure to dusts, smokes and air pollution as much as possible.4. Were I treating you, I would prescribe you an antihistamine like cetirizinelevocetirizinefexofenadinehydroxyzinepantoprazole before breakfast for 2 weeks.5. Regular steam inhalation with salbutamol can also be helpful.Hope above suggestions will be helpful to you.Should you have any further query, please feel free to ask at HCM.Wish you the best of the health ahead.Thank you & \n\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Generating text with raw GPT2","metadata":{"id":"B4UjMTwWx-ky"}},{"cell_type":"code","source":"tokenizer = get_tokenier()\nmodel = get_model(tokenizer)","metadata":{"id":"kbiaQldb1RPO","execution":{"iopub.status.busy":"2022-08-12T10:09:31.701705Z","iopub.execute_input":"2022-08-12T10:09:31.702241Z","iopub.status.idle":"2022-08-12T10:09:45.139857Z","shell.execute_reply.started":"2022-08-12T10:09:31.7022Z","shell.execute_reply":"2022-08-12T10:09:45.138868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompt = title\n\ngenerated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\ndevice = torch.device(\"cuda\")\ngenerated = generated.to(device)\n\nmodel.eval()\nsample_outputs = model.generate(generated, \n                                do_sample=True,   \n                                max_length=MAXLEN,                                                      \n                                num_beams=5,\n                                repetition_penalty=5.0,\n                                early_stopping=True,      \n                                num_return_sequences=1\n                                )\n\nfor i, sample_output in enumerate(sample_outputs):\n    print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))","metadata":{"id":"H1ag9Z0iZbzG","outputId":"1aab1e57-e34c-4988-9575-994d790c03cc","execution":{"iopub.status.busy":"2022-08-12T10:09:45.141657Z","iopub.execute_input":"2022-08-12T10:09:45.142053Z","iopub.status.idle":"2022-08-12T10:09:47.987869Z","shell.execute_reply.started":"2022-08-12T10:09:45.142016Z","shell.execute_reply":"2022-08-12T10:09:47.986737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}